{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure reproducibility\n",
    "Use a fixed seed such that all steps and results can be reproduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed handpicked to ensure all of the cleaning/pre-processing steps were visually shown\n",
    "SEED = 544\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. Simple Models\n",
    "In this section, we will use the word2vec features in the section above to train a perceptron and SVM for binary models. The input feature will be the average Word2Vec vectors for each review. Words with no encoding vector will be ignored. Furthermore, data cleaning and preprocessing steps similar of that in HW1 will be utilized. Finally, the dataset is split int 80%-20% training and testing split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "Load the pandas dataset from Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from disk\n",
    "data = pd.read_pickle('dataset.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load both Word2Vec models\n",
    "Load the w2v models from Q2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "w2v_google = api.load('word2vec-google-news-300')\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "w2v_own = KeyedVectors.load('my_w2v.w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the averaged input features for the reviews\n",
    "Input feature is the average Word2Vec vector for each review. Words with no encoding vectors are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the given review body text into the averaged Word2Vec vector using a given trained word2vec model\n",
    "def create_avg_input_feature(text, wv):\n",
    "    vec = np.zeros((300,), dtype=float)\n",
    "    count = 0\n",
    "    # Will skip words that have no vectors\n",
    "    for word in str(text).split():\n",
    "        if word in wv:\n",
    "            vec += np.array(wv[word])\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        vec /= count\n",
    "    return vec.tolist()\n",
    "\n",
    "# Create a new column for the review's input feature for both our w2v and googles w2v\n",
    "data['own_input_features'] = data['cleaned_reviews'].apply(\n",
    "    lambda text: create_avg_input_feature(text, w2v_own)\n",
    ")\n",
    "\n",
    "data['google_input_features'] = data['cleaned_reviews'].apply(\n",
    "    lambda text: create_avg_input_feature(text, w2v_google)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to report results for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def report_accuracy(text, y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'{text}: accuracy is {accuracy:.3f}.')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing data split\n",
    "Split the data into two distinct parts (80% training, 20% testing) so that there is no overlap. This is done to ensure no data leakage nor bias influences the training and we can have a better view of the training process (if it overfitted for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "binary_data = data[data['label'] <= 1] # Only select class 0 (positive) and class 1 (negative)\n",
    "own_input_features = [[col for col in row] for row in binary_data['own_input_features']]\n",
    "google_input_features = [[col for col in row] for row in binary_data['google_input_features']]\n",
    "binary_labels = binary_data['label']\n",
    "\n",
    "# Perform an 80-20 split for training and testing data on the binary data only\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(\n",
    "    binary_data['cleaned_reviews'],\n",
    "    binary_labels,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_tfidf)\n",
    "X_test_tfidf = vectorizer.transform(X_test_tfidf)\n",
    "\n",
    "X_train_own, X_test_own, y_train_own, y_test_own = train_test_split(\n",
    "    own_input_features,\n",
    "    binary_labels,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "X_train_google, X_test_google, y_train_google, y_test_google = train_test_split(\n",
    "    google_input_features,\n",
    "    binary_labels,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron - My Word2Vec Model\n",
    "Use our Word2Vec model as an input to the Perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Own W2C - Perceptron - Binary: accuracy is 0.737.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "model = Perceptron()\n",
    "model.fit(X_train_own, y_train_own)\n",
    "\n",
    "y_test_pred = model.predict(X_test_own)\n",
    "\n",
    "report_accuracy('Own W2C - Perceptron - Binary', y_test_own, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron - Google News Word2Vec Model\n",
    "Use pre-trained Word2Vec model as an input to the Perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google News W2V - Perceptron - Binary: accuracy is 0.787.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Perceptron()\n",
    "model.fit(X_train_google, y_train_google)\n",
    "\n",
    "y_test_pred = model.predict(X_test_google)\n",
    "\n",
    "report_accuracy('Google News W2V - Perceptron - Binary', y_test_google, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron - TF-IDF (HW1)\n",
    "Use TF-IDF Feature Extraction to train the Perceptron; identical to HW1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF - Perceptron - Binary: accuracy is 0.822.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Perceptron()\n",
    "model.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "y_test_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "report_accuracy('TF-IDF - Perceptron - Binary', y_test_tfidf, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron - Conclusion\n",
    "Our Word2Vec model achieved a testing accuracy of 0.737, whereas Google's model got 0.787. This difference is miniscule and we can conclude that our model is decent. When compared to HW1's TF-IDF approach, which scored testing accuracy of 0.822, we can see that Word2Vec falls shy behind. Nevertheless, they're all approximately 80% accuracy.\n",
    "\n",
    "Initially, I believed our model should be better than Google's model because our model was tailored specifically for the reviews and the dataset it used was that of the same domain, whereas Google's model used dataset for news and thus the semantic relationships could differ. However, our w2v was trained on data that had a lot of typos and other features that could harm the training whereas Googles had a more professional tone to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - My Word2Vec Model\n",
    "Use our Word2Vec model as an input to the SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanavesa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Own W2C - SVM - Binary: accuracy is 0.836.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = LinearSVC(max_iter=2500)\n",
    "model.fit(X_train_own, y_train_own)\n",
    "\n",
    "y_test_pred = model.predict(X_test_own)\n",
    "\n",
    "report_accuracy('Own W2C - SVM - Binary', y_test_own, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - Google News Word2Vec Model\n",
    "Use pre-trained Word2Vec model as an input to the SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google News W2V - SVM - Binary: accuracy is 0.819.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(max_iter=2500)\n",
    "model.fit(X_train_google, y_train_google)\n",
    "\n",
    "y_test_pred = model.predict(X_test_google)\n",
    "\n",
    "report_accuracy('Google News W2V - SVM - Binary', y_test_google, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - TF-IDF (HW1)\n",
    "Use TF-IDF Feature Extraction to train the SVM; identical to HW1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF - SVM - Binary: accuracy is 0.870.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(max_iter=2500)\n",
    "model.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "y_test_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "report_accuracy('TF-IDF - SVM - Binary', y_test_tfidf, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - Conclusion\n",
    "Our Word2Vec model achieved a testing accuracy of 0.836, whereas Google's model got 0.819. While this difference is small, our model performed better in SVM than in Perceptron. Moreover, when compared to HW1's TF-IDF approach, which scored testing accuracy of 0.870, we can see that Word2Vec falls shy behind aswell. Nevertheless, they're all approximately 85% accuracy. TF-IDF still reigns supreme in both SVM and Perceptron.\n",
    "\n",
    "Unlike before, I believe our model is better than Google's model because our model used a domain-specific dataset that was tailored for reviews whereas Google used a news dataset which is generic for this task"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
